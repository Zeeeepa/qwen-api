# ğŸš€ Qwen OpenAI Proxy - One-Command Deployment

Complete deployment guide for the Qwen OpenAI API Proxy - a universal OpenAI-compatible server that accepts **any API key** and **any model name**.

## âœ¨ Quick Start (3 commands!)

```bash
export QWEN_EMAIL="developer@pixelium.uk"
export QWEN_PASSWORD="developer1?"
git clone https://github.com/Zeeeepa/qwen-api
cd qwen-api
bash scripts/all.sh
```

That's it! Your server will be running at `http://localhost:7000` ğŸ‰

## ğŸ“‹ What Does It Do?

The deployment script automatically:

1. âœ… Installs system dependencies (Python, curl, jq, etc.)
2. âœ… Sets up Python virtual environment
3. âœ… Installs all Python packages
4. âœ… Installs Playwright browsers
5. âœ… Extracts your Qwen authentication token
6. âœ… Validates the token
7. âœ… Starts the OpenAI-compatible API server

## ğŸ¯ Key Features

### Universal Compatibility
- âœ… **Any API key works** - Server uses its own stored token
- âœ… **Any model name works** - Maps to qwen3-max automatically
- âœ… **OpenAI SDK compatible** - Drop-in replacement
- âœ… **No configuration needed** - Just provide credentials and go!

### Supported Models
```
User Requests:       Server Maps To:
----------------     ---------------
gpt-5           â†’    qwen3-max
GLM-4.5V        â†’    qwen3-max
claude-3        â†’    qwen3-max
o1              â†’    qwen3-max
qwen3-max       â†’    qwen3-max (use actual model)
qwen3-coder-plusâ†’    qwen3-coder-plus
...any model... â†’    qwen3-max (default)
```

## ğŸ’» Usage Examples

### Python (OpenAI SDK)

```python
from openai import OpenAI

# ANY API key works - server ignores it!
client = OpenAI(
    api_key="sk-anything-you-want",  # Can be random!
    base_url="http://localhost:7000/v1"
)

# ANY model name works - maps to qwen3-max!
response = client.chat.completions.create(
    model="gpt-5",  # Or GLM-4.5V, claude-3, etc.
    messages=[
        {"role": "user", "content": "Write a haiku about code"}
    ]
)

print(response.choices[0].message.content)
```

### cURL

```bash
curl -X POST http://localhost:7000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer sk-any" \
  -d '{
    "model": "gpt-5",
    "messages": [{"role": "user", "content": "Hello!"}]
  }'
```

### JavaScript/TypeScript

```javascript
import OpenAI from 'openai';

const client = new OpenAI({
    apiKey: 'sk-whatever',  // Any key works!
    baseURL: 'http://localhost:7000/v1'
});

const response = await client.chat.completions.create({
    model: 'gpt-5',  // Any model works!
    messages: [{ role: 'user', content: 'Hello!' }]
});

console.log(response.choices[0].message.content);
```

## ğŸ”§ Configuration

### Environment Variables

```bash
# Required (for token extraction)
export QWEN_EMAIL="your@email.com"
export QWEN_PASSWORD="yourpassword"

# Optional
export PORT=7000  # Default port (optional)
```

### Custom Port

```bash
PORT=8080 bash scripts/all.sh
```

## ğŸ“Š Server Management

### View Logs
```bash
tail -f server.log
```

### Stop Server
```bash
kill $(cat server.pid)
```

### Restart Server
```bash
bash scripts/all.sh
```

### Check Server Status
```bash
curl http://localhost:7000/v1/models
```

## ğŸ› Troubleshooting

### Server Won't Start

1. Check logs:
   ```bash
   tail -50 server.log
   ```

2. Verify token is valid:
   ```bash
   source .env
   python3 py-api/qwen-api/check_jwt_expiry.py "$QWEN_BEARER_TOKEN" --verbose
   ```

3. Check if port is in use:
   ```bash
   lsof -i :7000
   ```

### Token Expired

Re-run the deployment script to get a fresh token:
```bash
bash scripts/all.sh
```

### Dependencies Missing

Install manually:
```bash
# Ubuntu/Debian
sudo apt-get update
sudo apt-get install -y python3 python3-pip python3-venv curl git jq

# macOS
brew install python3 curl jq

# Then run deployment again
bash scripts/all.sh
```

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User Request   â”‚
â”‚  (any API key)  â”‚
â”‚  (any model)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Qwen OpenAI Proxy      â”‚
â”‚  (localhost:7000)       â”‚
â”‚                         â”‚
â”‚  â€¢ Ignores user API key â”‚
â”‚  â€¢ Maps model names     â”‚
â”‚  â€¢ Uses stored token    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Qwen API               â”‚
â”‚  (qwen.aikit.club)      â”‚
â”‚                         â”‚
â”‚  â€¢ Receives proxied req â”‚
â”‚  â€¢ Uses server token    â”‚
â”‚  â€¢ Uses mapped model    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ Files Structure

```
qwen-api/
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ all.sh           # One-command deployment
â”œâ”€â”€ py-api/
â”‚   â”œâ”€â”€ start.py         # Server entry point
â”‚   â”œâ”€â”€ setup.py         # Package config
â”‚   â””â”€â”€ qwen-api/
â”‚       â”œâ”€â”€ qwen_openai_server.py   # Main server
â”‚       â”œâ”€â”€ get_qwen_token.py       # Token extraction
â”‚       â””â”€â”€ check_jwt_expiry.py     # Token validation
â”œâ”€â”€ .env                 # Environment variables (auto-generated)
â”œâ”€â”€ server.log          # Server logs (auto-generated)
â”œâ”€â”€ server.pid          # Server PID (auto-generated)
â””â”€â”€ DEPLOYMENT.md       # This file
```

## ğŸ” Security Notes

- âœ… Token is extracted automatically during deployment
- âœ… Token is stored in `.env` file (gitignored)
- âœ… Server uses stored token for all requests
- âœ… User API keys are ignored (not stored or logged)
- âš ï¸ Keep your `.env` file secure
- âš ï¸ Don't commit `.env` to version control

## ğŸŒŸ Advanced Usage

### Use Specific Qwen Models

```python
from openai import OpenAI

client = OpenAI(
    api_key="sk-any",
    base_url="http://localhost:7000/v1"
)

# Use Qwen's best coder model
response = client.chat.completions.create(
    model="qwen3-coder-plus",
    messages=[{"role": "user", "content": "Write Python code for quicksort"}]
)

# Use Qwen's vision model
response = client.chat.completions.create(
    model="qwen3-vl-plus",
    messages=[{"role": "user", "content": "Describe this image: ..."}]
)
```

### Available Qwen Models

- `qwen3-max` - Best general-purpose model
- `qwen3-coder-plus` - Best for coding tasks
- `qwen3-vl-plus` - Vision + Language model
- `qwen2.5-72b-instruct` - Large instruction-following model
- `qwen2.5-coder-32b-instruct` - Coding specialist

## ğŸ†˜ Support

- ğŸ“– [GitHub Issues](https://github.com/Zeeeepa/qwen-api/issues)
- ğŸ’¬ [Discussions](https://github.com/Zeeeepa/qwen-api/discussions)
- ğŸ“§ Email: developer@pixelium.uk

## ğŸ“ License

MIT License - see LICENSE file for details

---

**Made with â¤ï¸ for the AI developer community**

